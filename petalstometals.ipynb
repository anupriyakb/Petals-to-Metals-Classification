{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing the required libraires\nimport numpy as np \nimport re\nimport pandas as pd\nimport os,glob\nimport tensorflow as tf\nimport keras\nfrom keras.layers import Input,Dense\nfrom keras.models import Model,load_model\nimport math\nfrom keras.applications import InceptionV3,VGG19,Xception,DenseNet201\nfrom keras.layers.pooling import GlobalAveragePooling2D\nimport pathlib\nfrom matplotlib import pyplot as plt","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#retrieve public GCS paths from a public Kaggle dataset\nfrom kaggle_datasets import KaggleDatasets","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)","execution_count":3,"outputs":[{"output_type":"stream","text":"Device: grpc://10.0.0.2:8470\nNumber of replicas: 8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReadData():\n    \n    def __init__(self):\n        self.input_shape = [192,192,3]\n        self.epochs = 25\n        self.batch_size = 16 * strategy.num_replicas_in_sync\n        \n        self.GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n        \n        self.training_path = tf.io.gfile.glob(self.GCS_DS_PATH + '/tfrecords-jpeg-192x192/train/*.tfrec')\n        self.validation_path = tf.io.gfile.glob(self.GCS_DS_PATH + '/tfrecords-jpeg-192x192/val/*.tfrec')\n        self.test_path = tf.io.gfile.glob(self.GCS_DS_PATH + '/tfrecords-jpeg-192x192/test/*.tfrec')\n        \n       \n        \n    def count_images(filenames):\n        return np.sum([int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames])\n\n        \n    def read_label_records(self,data):\n        label_feature = {\n             \"image\":tf.io.FixedLenFeature([],tf.string),\n             \"class\":tf.io.FixedLenFeature([],tf.int64)\n            \n        }\n        decoded = tf.io.parse_single_example(data,label_feature)\n        \n        image = tf.image.decode_jpeg(decoded['image'],channels=3)\n        image = tf.cast(image,tf.float32)/255.0\n        image = tf.reshape(image,self.input_shape)\n        label = tf.cast(decoded['class'], tf.int32) #decoded['class']\n        \n        return image,label\n    \n    def read_unlabeled_records(self,data):\n        label_feature = {\n             \"image\":tf.io.FixedLenFeature([],tf.string),\n             \"id\":tf.io.FixedLenFeature([],tf.string)\n            \n        }\n        decoded = tf.io.parse_single_example(data,label_feature)\n        \n        image = tf.image.decode_jpeg(decoded['image'],channels=3)\n        image = tf.cast(image,tf.float32)/255.0\n        image = tf.reshape(image,self.input_shape)\n        label = decoded['id'] #decoded['class']\n        \n        return image,label\n    \n    \n    \n    def load_dataset(self,filename,labeled=True,ordered=False):\n        option_order = tf.data.Options()\n        option_order.experimental_deterministic = False\n        \n        dataset = tf.data.TFRecordDataset(filename)\n        dataset = dataset.with_options(option_order)\n        dataset = dataset.map(self.read_label_records if labeled else self.read_unlabeled_records)\n        return dataset\n        \n    def get_training_data(self):\n        dataset = self.load_dataset(self.training_path,labeled=True,ordered=False)\n        dataset = dataset.repeat()\n        dataset = dataset.shuffle(2048)\n        dataset = dataset.batch(self.batch_size)\n        return dataset\n    \n    def get_validation_data(self):\n        dataset = self.load_dataset(self.validation_path,labeled=True,ordered=False)\n        dataset = dataset.batch(self.batch_size)\n        dataset = dataset.cache()\n        return dataset\n    \n    def get_test_data(self):\n        dataset =self.load_dataset(self.test_path,labeled=False,ordered=True)\n        dataset = dataset.batch(self.batch_size)\n        return dataset\n    \n    GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n    training_path = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-192x192/train/*.tfrec')\n    validation_path = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-192x192/val/*.tfrec')\n    test_path = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-192x192/test/*.tfrec')\n    \n    num_training_samples = count_images(training_path)\n    num_validation_samples = count_images(validation_path)\n    num_testing_samples = count_images(test_path)    ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Base_Model():\n    model = ''\n    history = ''\n    \n    def fit_model(self):\n        with strategy.scope():\n            read_cls = ReadData()\n            self.input_shape = [192,192,3]\n            self.epochs = 25\n            \n        \n            \n            self.batch_size = 16 * strategy.num_replicas_in_sync\n            self.train_images_count = read_cls.num_training_samples\n            self.test_image_count = read_cls.num_testing_samples\n            self.steps_per_epoch = self.train_images_count // self.batch_size\n            \n            \n\n            self.base_model = DenseNet201(weights='imagenet',include_top=False,input_shape=self.input_shape)\n            self.base_model.trainable = False\n              \n            global model,history\n            \n            model = tf.keras.Sequential([self.base_model,tf.keras.layers.GlobalAveragePooling2D(),\n                                                tf.keras.layers.Dense(104, activation='softmax')])\n            \n            #opt = keras.optimizers.Adam(learning_rate=0.01)\n            model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n                              metrics=['accuracy']) \n                \n            history = model.fit_generator(read_cls.get_training_data(),\n                                       steps_per_epoch=self.steps_per_epoch,\n                                       epochs=self.epochs,validation_data=read_cls.get_validation_data())\n            \n            self.generate_result()\n            \n    def generate_result(self):\n        read_cls = ReadData()\n        \n        test_dataset =  read_cls.get_test_data()\n        test = test_dataset.map(lambda image, label: image)\n        test_predict = model.predict(test)    \n        test_predict = np.argmax(test_predict, axis=-1)\n            \n        test_dataset = read_cls.get_test_data()\n        test_ids_ds = test_dataset.map(lambda image, label: label).unbatch()\n        test_ids = next(iter(test_ids_ds.batch(read_cls.num_testing_samples))).numpy().astype('U')\n            \n        submission = pd.DataFrame(test_ids, columns=['id'])\n        submission['label'] = test_predict\n        \n        submission.to_csv('submission.csv', index=False)\n        \n        # plotting the graph\n        self.plot_acc_graph()\n        \n    def plot_acc_graph(self):\n        acc = history.history['accuracy']\n        val_acc = history.history['val_accuracy']\n        loss = history.history['loss']\n        val_loss = history.history['val_loss']\n        epochs=range(len(acc))\n        \n        fig = plt.figure(figsize=(5,5))\n        plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n        plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.title('Training and validation accuracy')\n        plt.legend(loc='lower right')\n        plt.show()\n        fig.savefig('Accuracy Plot.jpg')\n        \n        self.plot_loss_graph()\n        \n    def plot_loss_graph(self):\n                    \n        acc = history.history['accuracy']\n        val_acc = history.history['val_accuracy']\n        loss = history.history['loss']\n        val_loss = history.history['val_loss']\n        epochs=range(len(acc))\n        \n        fig2 = plt.figure(figsize=(5,5))\n        plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n        plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n        plt.legend(loc='upper right')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.title('Training and validation loss')\n        plt.show()\n        fig2.savefig('Loss Plot.jpg')\n        \n            ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Base_Model().fit_model()","execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ResNet152V2' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-84a7feec45a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBase_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-3d5d82dd4da9>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet152V2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ResNet152V2' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}